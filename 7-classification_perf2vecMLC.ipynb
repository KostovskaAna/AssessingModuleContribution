{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "elitist\n",
      "mirrored\n",
      "base_sampler\n",
      "weights_option\n",
      "local_restart\n",
      "step_size_adaptation\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n",
      "mutation_base\n",
      "mutation_reference\n",
      "mutation_n_comps\n",
      "use_archive\n",
      "crossover\n",
      "adaptation_method\n",
      "lpsr\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def classification_perf2vec(clf, clf_name, modAlgo, log_mode):\n",
    "    dims = [5, 30]\n",
    "    modules = ['elitist', 'mirrored', 'base_sampler', 'weights_option', 'local_restart', 'step_size_adaptation'] if modAlgo == 'modCMA' else ['mutation_base','mutation_reference','mutation_n_comps','use_archive','crossover','adaptation_method','lpsr']\n",
    "    df = pd.read_csv(f'./data/classification_data/{modAlgo}_conf_perf2vec_{log_mode}.csv', index_col = 0)\n",
    "    df_grid = pd.read_csv(f'./data/raw_data/{modAlgo}_conf_grid.csv', index_col=0)\n",
    "\n",
    "    columns = ['module', 'dim', 'budget', 'acc', 'f1', 'acc_d', 'f1_d']\n",
    "    data = []\n",
    "    for dim in dims:\n",
    "        budgets = [50*dim, 100*dim, 300*dim, 500*dim, 1000*dim, 1500*dim]\n",
    "        for budget in budgets:\n",
    "            variable = f'.*_{budget}_{dim}'           \n",
    "            df_sub = df[df.index.str.contains(fr'\\b{variable}\\b', regex=True)]\n",
    "            df_sub.index = [ int(i.split(\"_\")[0]) for i in df_sub.index]\n",
    "            df_sub = df_sub.join(df_grid)\n",
    "            df_sub = df_sub.replace({np.nan: 'N'})\n",
    "\n",
    "\n",
    "            y = df_sub.iloc[:,-len(modules):] \n",
    "            X = df_sub.drop(modules, axis=1)\n",
    "  \n",
    "\n",
    "            kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            # clf = RandomForestClassifier(random_state=42)\n",
    "            dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "            accuracy_scores = [[] for _ in range(len(modules))]\n",
    "            f1_scores = [[] for _ in range(len(modules))]\n",
    "            accuracy_scores_dummy = [[] for _ in range(len(modules))]\n",
    "            f1_scores_dummy = [[] for _ in range(len(modules))]\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                y_train = y_train.replace({True: \"true\", False: \"false\"})\n",
    "                y_test = y_test.replace({True: \"true\", False: \"false\"})\n",
    "                y_train = y_train.replace({1: \"one\", 2: \"two\"})\n",
    "                y_test = y_test.replace({1: \"one\", 2: \"two\"})\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_test).tolist()\n",
    "\n",
    "                for N in range(0, len(modules)):\n",
    "                    y_pred_module = [row[N] for row in y_pred]\n",
    "                    y_test_module = list(y_test[modules[N]])\n",
    "\n",
    "                    acc = accuracy_score(y_test_module, y_pred_module)\n",
    "                    f1 = f1_score(y_test_module, y_pred_module, average = 'macro')\n",
    "                    accuracy_scores[N].append(acc)\n",
    "                    f1_scores[N].append(f1)\n",
    "\n",
    "                dummy.fit(X_train, y_train)\n",
    "                y_pred_dummy = dummy.predict(X_test).tolist()\n",
    "                for N in range(0, len(modules)):\n",
    "                    y_pred_dummy_module = [row[N] for row in y_pred_dummy]\n",
    "                    y_test_module = list(y_test[modules[N]])\n",
    "\n",
    "                    acc_dummy = accuracy_score(y_test_module, y_pred_dummy_module)\n",
    "                    f1_score_dummy = f1_score(y_test_module, y_pred_dummy_module, average = 'macro')\n",
    "                    accuracy_scores_dummy[N].append(acc_dummy)\n",
    "                    f1_scores_dummy[N].append(f1_score_dummy)\n",
    "\n",
    "\n",
    "\n",
    "            for N in range(0, len(modules)):\n",
    "                acc = np.mean(accuracy_scores[N])\n",
    "                f1 = np.mean(f1_scores[N])\n",
    "                acc_d = np.mean(accuracy_scores_dummy[N])\n",
    "                f1_d = np.mean(f1_scores_dummy[N])\n",
    "\n",
    "                data.append([modules[N], dim, budget, acc, f1, acc_d, f1_d])\n",
    "                print(modules[N])\n",
    "                # print(\"dim_\"+str(dim)+\"    budget_\"+str(budget))\n",
    "                # print(\"acc = \"+str(acc))\n",
    "                # print(\"acc_dummy = \"+str(acc_d))\n",
    "                # print(\"f1 = \"+str(f1))\n",
    "                # print(\"f1_dummy = \"+str(f1_d))\n",
    "    df_class = pd.DataFrame(data=data, columns=columns)\n",
    "    df_class.to_csv(f'./results/{modAlgo}/classification_p2v_{clf_name}_MLC.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "classification_perf2vec(clf, 'RF', 'modCMA', 'log')\n",
    "classification_perf2vec(clf, 'RF', 'modDE', 'log')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('gecco2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c89a74c738d6b86f6a86a5c2beae296fa07f6fa7604ded0c128cb198698d1e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
